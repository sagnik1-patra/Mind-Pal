{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4047a77e-64af-4be3-bf64-2fc4c8cade42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--in IN_CSV] [--out OUT_CSV] [--text SINGLE_TEXT] [--print]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\sagni\\AppData\\Roaming\\jupyter\\runtime\\kernel-df4e8e00-2b12-430b-9490-6a2edfb25a2e.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3678: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# === predict_mood.py ===\n",
    "# Predict mood/emotion labels on new data using previously trained MindPal artifacts.\n",
    "# Outputs: predictions_mood.csv with columns:\n",
    "#   id, top1_label, top1_prob, [prob_<class_1>, prob_<class_2>, ...]\n",
    "#\n",
    "# Usage:\n",
    "#   python predict_mood.py --in \"C:\\Users\\sagni\\Downloads\\Mind Pal\\archive\\new_data.csv\" --out \"C:\\Users\\sagni\\Downloads\\Mind Pal\\predictions_mood.csv\"\n",
    "#   python predict_mood.py --text \"I felt calm and focused during study.\"\n",
    "#\n",
    "# Notes:\n",
    "# - The input CSV should have the SAME feature columns as training (except the target).\n",
    "# - If you use --text, weâ€™ll build a single-row DataFrame and put the text into the first text column\n",
    "#   we detect from the preprocess bundle; the rest will be left missing (imputers handle it).\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# -----------------------------\n",
    "# Default artifact paths\n",
    "# -----------------------------\n",
    "OUT_DIR   = r\"C:\\Users\\sagni\\Downloads\\Mind Pal\"\n",
    "PKL_PATH  = os.path.join(OUT_DIR, \"mindpal_preprocess.pkl\")\n",
    "H5_PATH   = os.path.join(OUT_DIR, \"mindpal_model.h5\")\n",
    "\n",
    "# -----------------------------\n",
    "# Helper classes (must match training script)\n",
    "# -----------------------------\n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Select a single column as a 2D DataFrame.\"\"\"\n",
    "    def __init__(self, column):\n",
    "        self.column = column\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[[self.column]]\n",
    "\n",
    "class To1DString(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Convert a 2D array/DataFrame (n,1) to 1D array[str] for text vectorizers.\"\"\"\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            arr = X.iloc[:, 0].astype(str).values\n",
    "        else:\n",
    "            arr = np.asarray(X).astype(str).ravel()\n",
    "        return arr\n",
    "\n",
    "class DateTimeExpand(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Expand datetime columns into year/month/day/dow numeric features.\"\"\"\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "        self.out_cols = []\n",
    "    def fit(self, X, y=None):\n",
    "        self.out_cols = []\n",
    "        for c in self.columns:\n",
    "            self.out_cols += [f\"{c}_year\", f\"{c}_month\", f\"{c}_day\", f\"{c}_dow\"]\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        outs = []\n",
    "        for c in self.columns:\n",
    "            s = pd.to_datetime(X[c], errors=\"coerce\")\n",
    "            outs.append(pd.DataFrame({\n",
    "                f\"{c}_year\":  s.dt.year.fillna(0).astype(int),\n",
    "                f\"{c}_month\": s.dt.month.fillna(0).astype(int),\n",
    "                f\"{c}_day\":   s.dt.day.fillna(0).astype(int),\n",
    "                f\"{c}_dow\":   s.dt.dayofweek.fillna(0).astype(int),\n",
    "            }))\n",
    "        return pd.concat(outs, axis=1) if outs else np.empty((len(X), 0))\n",
    "\n",
    "# -----------------------------\n",
    "# Utility\n",
    "# -----------------------------\n",
    "def load_bundle_and_model(pkl_path: str, h5_path: str):\n",
    "    if not os.path.exists(pkl_path):\n",
    "        raise FileNotFoundError(f\"Missing preprocess bundle: {pkl_path}\")\n",
    "    if not os.path.exists(h5_path):\n",
    "        raise FileNotFoundError(f\"Missing model file: {h5_path}\")\n",
    "\n",
    "    bundle = joblib.load(pkl_path)\n",
    "    model  = load_model(h5_path)\n",
    "    return bundle, model\n",
    "\n",
    "def build_df_for_text(single_text: str, bundle: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create a single-row DataFrame compatible with training columns.\n",
    "    Will place the provided text into the FIRST available text column.\n",
    "    \"\"\"\n",
    "    # Try to reconstruct the full input schema:\n",
    "    numeric_cols   = bundle.get(\"numeric_cols\", [])\n",
    "    cat_cols       = bundle.get(\"cat_cols\", [])\n",
    "    text_cols      = bundle.get(\"text_cols\", [])\n",
    "    datetime_cols  = bundle.get(\"datetime_cols\", [])\n",
    "\n",
    "    all_cols = list(dict.fromkeys(numeric_cols + cat_cols + text_cols + datetime_cols))\n",
    "\n",
    "    if not all_cols:\n",
    "        # Fallback: single 'text' column\n",
    "        all_cols = [\"text\"]\n",
    "\n",
    "    df = pd.DataFrame({c: [np.nan] for c in all_cols})\n",
    "\n",
    "    # Place text into the first text column (or 'text' if that was created)\n",
    "    if text_cols:\n",
    "        df[text_cols[0]] = single_text\n",
    "    else:\n",
    "        # Ensure a 'text' column exists\n",
    "        if \"text\" not in df.columns:\n",
    "            df[\"text\"] = [single_text]\n",
    "        else:\n",
    "            df.loc[0, \"text\"] = single_text\n",
    "\n",
    "    return df\n",
    "\n",
    "def ensure_dense_if_small(X):\n",
    "    if hasattr(X, \"toarray\"):\n",
    "        # Heuristic threshold to avoid RAM blow-ups\n",
    "        return X.toarray() if X.shape[1] <= 50000 else X\n",
    "    return X\n",
    "\n",
    "def predict_dataframe(df_in: pd.DataFrame, bundle: dict, model) -> pd.DataFrame:\n",
    "    preprocess     = bundle[\"preprocess\"]\n",
    "    label_encoder  = bundle[\"label_encoder\"]\n",
    "    target_col     = bundle.get(\"target_col\", None)\n",
    "\n",
    "    X = df_in.copy()\n",
    "    if target_col and target_col in X.columns:\n",
    "        X = X.drop(columns=[target_col])\n",
    "\n",
    "    X_t = preprocess.transform(X)\n",
    "    X_t = ensure_dense_if_small(X_t)\n",
    "\n",
    "    probs = model.predict(X_t, verbose=0)\n",
    "    classes = [str(c) for c in label_encoder.classes_]\n",
    "\n",
    "    if probs.ndim == 1 or probs.shape[1] == 1:\n",
    "        # Binary case: probs is (N,1); construct 2-class distribution (class_1 is \"positive\")\n",
    "        pos = probs.ravel()\n",
    "        neg = 1.0 - pos\n",
    "        probs_mat = np.vstack([neg, pos]).T\n",
    "        # label_encoder.classes_ defines order; assume positive prob aligns with the second class\n",
    "        top_idx = (pos >= 0.5).astype(int)\n",
    "    else:\n",
    "        probs_mat = probs\n",
    "        top_idx = np.argmax(probs_mat, axis=1)\n",
    "\n",
    "    top_label = [classes[i] for i in top_idx]\n",
    "    top_prob  = probs_mat[np.arange(len(probs_mat)), top_idx]\n",
    "\n",
    "    # Build output frame\n",
    "    out = pd.DataFrame({\n",
    "        \"id\": np.arange(len(df_in)),\n",
    "        \"top1_label\": top_label,\n",
    "        \"top1_prob\": top_prob\n",
    "    })\n",
    "\n",
    "    # Add per-class probability columns\n",
    "    for j, cls in enumerate(classes):\n",
    "        out[f\"prob_{cls}\"] = probs_mat[:, j]\n",
    "\n",
    "    return out\n",
    "\n",
    "# -----------------------------\n",
    "# Main\n",
    "# -----------------------------\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"Predict mood/emotion labels with MindPal model.\")\n",
    "    parser.add_argument(\"--in\",  dest=\"in_csv\",  type=str, default=None,\n",
    "                        help=\"Path to input CSV with same columns as training (except target).\")\n",
    "    parser.add_argument(\"--out\", dest=\"out_csv\", type=str, default=None,\n",
    "                        help=\"Where to save predictions CSV. Defaults to 'predictions_mood.csv' in OUT_DIR.\")\n",
    "    parser.add_argument(\"--text\", dest=\"single_text\", type=str, default=None,\n",
    "                        help=\"Predict on a single text string (optional).\")\n",
    "    parser.add_argument(\"--print\", dest=\"do_print\", action=\"store_true\",\n",
    "                        help=\"Print top predictions to console.\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    bundle, model = load_bundle_and_model(PKL_PATH, H5_PATH)\n",
    "\n",
    "    # Build input DataFrame\n",
    "    if args.single_text is not None:\n",
    "        df_in = build_df_for_text(args.single_text, bundle)\n",
    "    elif args.in_csv is not None:\n",
    "        if not os.path.exists(args.in_csv):\n",
    "            raise FileNotFoundError(f\"Input CSV not found: {args.in_csv}\")\n",
    "        df_in = pd.read_csv(args.in_csv)\n",
    "    else:\n",
    "        raise ValueError(\"Provide either --text 'your sentence' or --in path\\\\to\\\\file.csv\")\n",
    "\n",
    "    preds = predict_dataframe(df_in, bundle, model)\n",
    "\n",
    "    # Default output path\n",
    "    out_csv = args.out_csv or os.path.join(OUT_DIR, \"predictions_mood.csv\")\n",
    "    preds.to_csv(out_csv, index=False, encoding=\"utf-8\")\n",
    "    print(f\"[SAVE] Predictions -> {out_csv}\")\n",
    "\n",
    "    if args.do_print:\n",
    "        # Print first few rows\n",
    "        cols_to_show = [\"id\", \"top1_label\", \"top1_prob\"] + \\\n",
    "            [c for c in preds.columns if c.startswith(\"prob_\")]\n",
    "        print(preds[cols_to_show].head(10).to_string(index=False))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bed429-1001-4c3e-88c7-9d09bab10ec3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (moviepy)",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
